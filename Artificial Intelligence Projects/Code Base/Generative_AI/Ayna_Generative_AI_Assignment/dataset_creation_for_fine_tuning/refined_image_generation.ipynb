{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/vchopra/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')\n",
    "# ! export HF_TOKEN= ''\n",
    "! export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A young woman standing in a sunflower field, wearing a wide-brimmed hat and a flowing white dress, the sun setting behind her.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_prompt(FILE_PATH):\n",
    "    with open(FILE_PATH, 'r') as f:\n",
    "        data=f.read()\n",
    "    data=data.split('\\n')\n",
    "    data = list(filter(None, data))\n",
    "    return data\n",
    "\n",
    "data=read_prompt('./prompts.txt')\n",
    "basic_single_prompt=data[0]\n",
    "prompt = basic_single_prompt\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "import torchvision.transforms as transforms \n",
    "import gc\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After exiting the block, clear cache and garbage\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Enable suppression of errors encountered by TorchDynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "os.environ['TORCH_LOGS'] = \"+dynamo\"\n",
    "os.environ['TORCHDYNAMO_VERBOSE'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3833efb4b5f43269e843465e5dce6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load both base & refiner\n",
    "base = DiffusionPipeline.from_pretrained(\n",
    "    model_id, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "# base.to(\"cuda\")\n",
    "base.enable_model_cpu_offload()\n",
    "# base.unet = torch.compile(base.unet, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd32acd54f0d4a728123a7e15257e123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "refiner = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
    "    text_encoder_2=base.text_encoder_2,\n",
    "    vae=base.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    ")\n",
    "# refiner.to(\"cpu\")\n",
    "refiner.enable_model_cpu_offload()\n",
    "# refiner.unet = torch.compile(refiner.unet, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many steps and what % of steps to be run on each experts (80/20) here\n",
    "n_steps = 1000\n",
    "high_noise_frac = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_refined_image(prompt, image):\n",
    "    # After exiting the block, clear cache and garbage\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    image = refiner(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    denoising_start=high_noise_frac,\n",
    "    image=image,\n",
    "    ).images[0]\n",
    "    return image\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.PILToTensor() \n",
    "]) \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_NOISY_IMAGES=os.path.join(os.getcwd(),'noisy-images')\n",
    "LIST_OF_FILES=os.listdir(PATH_TO_NOISY_IMAGES)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/vchopra/DATA/Complete Technical Work/All  Projects Implemented/Small Projects/Artificial Intelligence/Code Base/Computer_Vision_Projects/Ayna_Generative_AI_Assignment/dataset_creation/noisy-images/prompt-1.jpeg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_file=os.path.join(PATH_TO_NOISY_IMAGES,LIST_OF_FILES[0])\n",
    "current_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[200, 173,  64,  ...,  89,  85, 185],\n",
       "         [ 79,  44,  97,  ..., 130, 151, 193],\n",
       "         [ 25, 187,  40,  ..., 165, 255, 198],\n",
       "         ...,\n",
       "         [140, 255, 133,  ...,  47, 213, 199],\n",
       "         [117, 142, 106,  ...,   8, 171, 218],\n",
       "         [ 74, 101,  56,  ...,   0,  37, 231]],\n",
       "\n",
       "        [[137, 146,  63,  ...,  78, 103, 221],\n",
       "         [139,  50,  62,  ..., 131, 106, 106],\n",
       "         [186, 233,   0,  ..., 163, 165,  26],\n",
       "         ...,\n",
       "         [ 37, 230, 123,  ...,  64, 197, 136],\n",
       "         [ 63, 146, 129,  ...,  85, 163,  88],\n",
       "         [136, 173, 105,  ..., 120,  54,  79]],\n",
       "\n",
       "        [[ 70, 199, 183,  ..., 108, 105, 209],\n",
       "         [ 43,  38, 102,  ...,  97, 113, 175],\n",
       "         [ 80, 160,   0,  ..., 104, 187, 146],\n",
       "         ...,\n",
       "         [  0, 163,  62,  ..., 152, 255, 155],\n",
       "         [ 77,  85,  25,  ..., 165, 186,  72],\n",
       "         [249, 125,   0,  ..., 171,  12,   3]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor = transform(Image.open(current_file))\n",
    "img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A young woman standing in a sunflower field, wearing a wide-brimmed hat and a flowing white dress, the sun setting behind her.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bcbb78d65f435cb06f9e662dfca951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image=return_refined_image(prompt, img_tensor)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(LIST_OF_FILES)):\n",
    "    current_file=os.path.join(PATH_TO_NOISY_IMAGES,LIST_OF_FILES[i])\n",
    "    # transform = transforms.PILToTensor() \n",
    "    # Convert the PIL image to Torch tensor \n",
    "    img_tensor = transform(current_file)\n",
    "    image=return_refined_image(prompt, img_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
